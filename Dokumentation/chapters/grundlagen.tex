\chapter{Grundlagen}

Im folgenden Kapitel sollen konzeptionelle Grundlagen erläutert werden, welche für das Verständnis der Bachelorarbeit notwendig sind.
Dabei wird auf die Themen Requirements Engineering, Augmented Reality und die Software reQlab eingegangen.

  \section{Requirements Engineering}
  Die Bachelorarbeit soll sogenannte Requirements, also Anforderungen, visualisieren.
  Daher ist es für das Verständnis der Arbeit wichtig, die Grundlagen des Requirements Engineering zu kennen.

    \titleemph{Requirements}

    Grundlegend sind Requirements Anforderungen, die an ein System gestellt werden.
    Das International Requirements Engineering Board (IREB) definiert sie in ihrem Glossar mit drei Eigenschaften:
    \begin{itemize}
        \item Ein Bedürfnis eines Interesseneigners (Stakeholder).
        \item Eine Eigenschaft oder Fähigkeit, die ein System haben soll.
        \item Eine dokumentierte Repräsentation eines Bedürfnisses, einer Fähigkeit oder einer Eigenschaft.
    \end{itemize}
    \autocite[][Def. Anforderung]{ireb_cpre_glossary}

    Sie sollen also die Bedürfnisse der Stakeholder an das System repräsentieren und dokumentieren.

    Die Gestaltung von Requirements kann dabei je nach System und Anforderungen unterschiedlich sein. Chris Rupp nennt in ihrem Buch \glqq{}Requirements-Engineering und -Management\grqq{} einige Beispiele für verschiedene Formen für Requirements:
    \begin{itemize}
        \item User-Stories
        \item Use-Cases
        \item Stories
        \item formalisierte natürlichsprachliche Anforderungen
        \item Anforderungen in Form von Diagrammen (semiformales Modell)
    \end{itemize}
    \autocite[][S. 19]{Rupp2014}

    
    Natürlichsprachliche Anforderungen können sehr einfach selbst formuliert werden, sind dadurch jedoch auch anfällig für Missverständnisse und Unklarheiten.
    Das Ziel von reQlab ist es, diese Missverständnisse und Unklarheiten zu erkennen und so die Qualität der Anforderungen zu verbessern.
    Daher werden im Unfamg dieser Bachelorarbeit nur natürlichsprachliche Anforderungen genutzt.

    Zudem werden Requirements in funktionale und nicht-funktionale Requirements unterteilt.
    Funktionale Requirements beschreiben \glqq{}die Funktionen, die das System leisten soll, die Informationen die es verarbeiten soll; das gewünschte Verhalten, welches das System an den Tag legen soll.\grqq{} \autocite[][S. 12]{Hruschka2023}
    Nicht-funktionale Requirements hingegen beschreiben alle Requirements, die nicht funktionaler Natur sind, also beispielsweise Performance, Sicherheit oder Zuverlässigkeit.
    Peter Hruschka beschreibt in seinem Buch Funktionale Anforderungen mit der Frage: \glqq{}Was soll das System/Produkt tun?\grqq{}.
    Auch unterteilt er nicht-funktionale Anforderungen in die zwei Kategorien Qualitätsanforderungen (\glqq{}Wie gut? Wie schnell? Wie zuverlässig? ...\grqq{}) und Randbedingungen (\glqq{}Ressourcen, Wiederverwendung, Zukauf, geforderte Technologie ...\grqq{}) \grqq{} \autocite[][S. 13]{Hruschka2023}.
    Diese Unterteilung ist hilfreich zur Strukturierung der Anforderungen und könnte im User-Interface der Visualisierung genutzt werden, um die Anforderungen zu kategorisieren.
    
    \titleemph{Stakeholder}

    Stakeholder können \glqq{}Personen oder Organisationen sein, die die Anforderungen eines Systems beeinflussen oder die von dem System beeinflusst werden.\grqq{} \autocite[][]{ireb_cpre_glossary}.
    Beispielsweise wären die Endnutzer eines Systems Stakeholder, welche durch das System beeinflusst werden.
    Sie haben also ein Bedürfnis an das System, können dieses jedoch nicht selbst umsetzen.
    Im Gegensatz dazu stehen die Auftraggeber beziehungsweise der Produkteigner (Product Owner), welche das System entwickeln und die Anforderungen festlegen.

    Je nach der Größe und Komplexität des Systems kann es sehr viele Anforderungen geben.
    Durch die Menge an Anforderungen kann so schnell die Übersicht über das System und dessen Requirements verloren gehen, vor allem für Stakeholder, die nicht tagtäglich mit dem System arbeiten.

    \titleemph{System}

    Die IREB definiert ein System als \glqq{}Eine kohärente, abgrenzbare Menge von Elementen, die durch koordiniertes Handeln einen bestimmten Zweck erfüllen.\grqq{} \autocite[][]{ireb_cpre_glossary}
    Das Wort System ist dabei ein Überbegriff für Produkte, Services, Geräte, Prozeduren und Werkzeuge und kann sowohl physisch als auch virtuell sein.
    Daher wird auch in dieser Bachelorarbeit das Wort System als Überbegriff für alle Arten von Systemen genutzt.

    \titleemph{Requirements Engineering}

    Requirements-Engineering ist der Prozess, in dem Anforderungen an ein System erhoben, dokumentiert, analysiert, spezifiziert und validiert werden.
    Laut Chris Rupp besteht Requirements-Engineering dabei aus vier Haupttätigkeiten:
    \begin{itemize}
        \item Wissen vermitteln
        \item Gute Anforderungen herleiten
        \item Anforderungen vermitteln
        \item Anforderungen verwalten
    \end{itemize}
    \autocite[][S.20]{Rupp2014}

    Diese Bachelorarbeit soll versuchen einen neuen Ansatz in der Vermittlung von Anforderungen zu finden, um so langfristig die Qualität und Nützlichkeit der Anforderungen zu verbessern.
    Zudem soll die Visualisierung der Anforderungen helfen, bei großen Projekten die eine sehr große Zahl an Anforderungen besitzen, eine Übersicht über die Anforderungen zu erhalten und so eventuell eine bessere Kommunikation zwischen Stakeholdern und Entwicklern zu ermöglichen.

  \section{reQlab}

  Die Software reQlab ist ein Requirements-Engineering-Tool, welches von der IT-Designers GmbH entwickelt wird.
  Es dient dazu, Requirements automatisiert zu analysieren und zu bewerten.
  Dafür nutzt die Software ein Large-Language-Model (LLM), welches natürlichsprachliche Anforderungen analysiert und bewertet.
  Daher werden in reQlab alle Anforderungen als natürlichsprachliche Anforderungen verfasst um dann vom LLM verarbeitet werden zu können.
  Die Software analysiert diese Anforderungen und gibt eine begründete Bewertung aus, ob die Anforderung gut oder schlecht ist und gibt Verbesserungsvorschläge.
  Das Ziel von reQlab ist es, die Qualität der Anforderungen zu verbessern und so die Qualität des gesamten Systems zu steigern.


  \section{Virtuelle Realität}
  Für das Verständnis von Augmented Reality ist es wichtig, die Begriffe der virtuellen Realität zu kennen und zu verstehen.
  Dabei wird der Nutzer in eine virtuelle Welt versetzt, die durch Computer generiert wird.
  In virtueller Realität ist, im Gegensatz zu Augmented Reality die gesamte Umgebung digital.
  \autocite[vgl.][S.15]{Dalton2023}
  Zusätzlich wird unterschieden zwischen immersiver und nicht-immersiver virtueller Realität.
  Folgende auf den Nutzer bezogene Eigenschaften sind dabei Indikatoren für nicht-immersive virtuelle Realität:
  \begin{itemize}
    \item Der Nutzer steht nicht im Mittelpunkt.
    \item Der Nutzer ist nicht vollständig von digitalen Inhalten umgeben.
    \item Der Nutzer erfährt die virtuelle Realität als Beobachter anstatt als Teilnehmer.
  \end{itemize}
  Bei immersiver virtueller Realität sind alle äußeren Einflüsse so weit reduziert wie möglich und alle Indikatoren sollten auf immersive virtuelle Realität hinweisen.
  Der Nutzer sollte bei immersiver VR das Gefühl haben, sich selbst in der virtuellen Umgebung zu befinden \autocite[vgl.][S.23-24]{Wolfel2023}.

  \section{Augmented Reality}
  Augmented Reality (AR) ist eine Technologie, die die reale Welt mit digitalen Informationen erweitert.
  Dabei wird ein ähnlicher Ansatz wie bei Virtueller Realität verfolgt, jedoch wird die reale Welt nicht komplett ersetzt, sondern nur erweitert.
  Der Nutzer sieht also weiterhin seine reale Umgebung, diese wird aber durch digitale Informationen ergänzt.
  \begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/RV-Continuum.png}
    \caption{Realitäts-Virtualitäts-Kontinuum nach Milgram}
    \label{fig:rv-continuum}
  \end{figure}
  Auf dem Realitäts-Virtualitäts-Kontinuum von Milgram, welches, wie in Abbildung \ref{fig:rv-continuum} dargestellt, einen fließenden Übergang zwischen Realität und Virtualität beschreibt, liegt Augmented Reality zwischen der realen Welt und der virtuellen Welt \autocite[vgl.][S.9]{milgram1999}.
  Daher fällt Augmented Reality unter den Überbegriff der Mixed Reality, da die reale Welt mit der digitalen Welt gemischt wird.
  Für diese Erweiterung der Realität müssen die Anzeigegeräte auch Informationen über die echte Umgebung sammeln können.
  Will man beispielsweise virtuelle Objekte in die reale Welt einfügen, so muss das Anzeigegerät die eigene Position kontinuierlich bestimmen können und die Position und Rotation des virtuellen Objekts anhand der Bewegungen des Nutzers anpassen.

  Anzeigegeräte für Augmented Reality haben viele Gemeinsamkeiten mit Anzeigegeräten für Virtuelle Realität.
  Die Besonderheit von AR-Anzeigegeräten ist jedoch, dass sie die reale Welt mit digitalen Informationen erweitern.
  Das heißt sie müssen dem Nutzer auch eine Sicht auf die reale Welt ermöglichen und in diese Informationen einblenden.
  Beispielsweise kann das Display eines Anzeigegeräts transparent sein, sodass der Nutzer durch das Display hindurch sehen kann.
  Alternativ kann das Gerät eine oder mehrere Kameras besitzen, dessen Aufnahme auf undurchsichtige Bildschirme projiziert wird.
  Diese Methode nennt sich auch Image Passthrough.
  Es gibt verschiedene Arten von Anzeigegeräten, die für Augmented Reality genutzt werden können, wobei man allgemein zwischen 3 Haputkategorien unterscheiden kann: Head-Mounted Displays, Hand-Held-Devices und Spatial Displays \autocite[][S. 346]{Carmigniani2011}.
  Im Folgenden werden diese drei Kategorien genauer erläutert und einige Beispiele genannt.

  \subsection{Head-Mounted Displays}
    Head-Mounted Displays (HMDs) sind grundsätzlich Bildschirme, die direkt auf dem Kopf des Nutzers getragen werden.
    Durch ihre Nähe zu den Augen des Nutzers können sie ein großes Sichtfeld abdecken, ohne dabei selbst große Displays zu nutzen.
    Dadurch sind sie für volle Immersion im Normalfall kosteneffektiver als große Displays, wie bspw. eine Leinwand.


    \subsubsection{VR Headsets}

    Klassische VR-Headsets kann man sich vorstellen wie eine Skibrille mit 2 Bildschirmen, die auf dem Kopf getragen wird und üblicherweise 2 Displays hinter 2 Linsen hat, bzw. ein Display virtuell in 2 Displays aufteilt.
    Durch die 2 Bildschirme wird für jedes Auge ein eigenes Bild erzeugt, wodurch Inhalte in 3D dargestellt werden können.
    Außerdem können sie das volle Sichtfeld des Nutzers abdecken und so eine immersive Erfahrung schaffen.
    Jedoch entstehen durch die Nähe des Nutzers zu den Displays auch Probleme, wie bspw. der Screen-Door-Effekt, bei welchem die Zwischenräume zwischen den Pixeln sichtbar sind.
    Entscheidend dabei ist die Kennzahl der Pixel pro Grad (Pixel per Degree, PPD), welche angibt, wie viele Pixel auf einen Grad des Sichtfelds des Nutzers kommen.
    Eine Möglichkeit um die PPD zu erhöhen und so den Screen-Door-Effekt zu minimieren, ist das Einsetzen von Displays mit einer hohen Pixeldichte (Pixels per Inch, PPI).
    Beispielsweise hat die Oculus Quest 3 eine PPI von 1218 und erreicht damit einen PPD Wert von 25 Pixeln pro Grad \autocite[]{meta-quest-3}.
    Vergleichsweise hat das iPhone 15 Pro eine Pixeldichte von nur 460 PPI \autocite[]{iPhone15Pro-datenblatt}.

    Die Position des Headsets muss dabei kontinuierlich bestimmt werden, um die Bewegungen der Nutzer zu verfolgen und so die virtuelle Welt anpassen zu können.
    Das Tracking kann beispielsweise durch Basisstationen (bspw. bei der Valve Index) realisiert werden, welche im Raum verteilt werden und mithilfe von Kameras und Sensoren die Position des Headsets bestimmen.
    Eine andere, modernere Methode des Headset Trackings ist das Tracking durch Kameras im Headset (bspw. bei der Oculus Quest 3).
    Diese Kameras nehmen die Umgebung des Nutzers auf und können mithilfe dieser Daten kontinuierlich die Position des Headsets bestimmen.
    Die Interaktion mit der Umgebung wird dann meist mit Controllern realisiert, deren Position und Rotation ebenfalls kontinuierlich durch Tracking Stationen oder eigene Kameras bestimmt werden muss.
    In VR-Headsets mit eigenen Kameras ist es auch möglich, die Hände des Nutzers zu tracken und als Eingabegeräte zu nutzen.
    Dabei können dann bestimmte Gesten oder Handbewegungen als Eingaben interpretiert und zur Interaktion genutzt werden.
    
    Ursprünglich mussten VR-Headsets mit einem Computer verbunden werden, um die Rechenleistung für die Darstellung der Inhalte zu haben.
    Mit der Zeit wurden jedoch auch Standalone-VR-Headsets entwickelt, wie zum Beispiel das im Jahr 2024 auf den Markt gebrachte Apple Vision Pro.
    Diese verfügen über eine eigene Rechenleistung und können somit unabhängig von einem Computer genutzt werden.

    \begin{figure}[H]
      \centering
      \includegraphics[width=0.9\textwidth]{images/quest3_example.jpg}
      \caption{Oculus Quest 3 VR-Headset}
      \source{https://unsplash.com/de/fotos/ein-mann-der-auf-einem-stuhl-sitzt-und-eine-virtuelle-brille-tragt-AZ-ND5uJ4S4}
      \label{fig:oculus-quest-3}
    \end{figure}

    Jedoch sind nicht alle VR-Headsets für AR geeignet.
    Die meisten VR-Headsets besitzen keine Kamera, um die reale Welt aufzunehmen und dem Nutzer wiederzugeben.
    Nur Headsets wie bspw. die Oculus Quest 3, welche in Abbildung \ref{fig:oculus-quest-3} dargestellt ist, oder die Apple Vision Pro besitzen eine Kamera nach außen, um die reale Welt aufzunehmen und so AR zu ermöglichen.
    
    Durch all diese Technik, können die neusten VR-Headsets eine sehr hohe Immersion und audiovisuelle Qualität für Anwendungen in AR bieten.
    Sie sind besonders dafür geeignet hochauflösende dreidimensionale Inhalte in die reale Welt zu projizieren und so eine immersive Erfahrung zu schaffen.
    Doch für lange Anwendungszeiten und die Verwendung in der Öffentlichkeit sind sie meist zu groß und schwer.

   

    \subsubsection{Smart-Glasses}

    Smart-Glasses sind Brillen, die digitale Informationen in das Sichtfeld des Nutzers einblenden.
    Sie zeichnen sich durch die Transparenz bzw. Semi-Transparenz der Displays aus, sodass der Nutzer auch durch die Displays hindurch sehen kann.
    So kann auch ohne digitales Image-Passthrough ein AR-Effekt erzielt werden.
    Die Durchsicht durch die Displays sind zudem meist schärfer als bei Image-Passthrough in VR-Headsets, da direkt die echte reale Welt gesehen wird und nicht eine Kameraaufnahme.

    Smart-Glasses sind außerdem meist leichter und kleiner als VR-Headsets, da sie meist nicht das volle Sichtfeld des Nutzers abdecken müssen und die Technik für Image-Passthrough nicht benötigt wird.
    Dadurch sind sie besser für den Alltag und für längere Anwendungszeiten geeignet als konventionelle VR- oder AR-Headsets.




  \subsection{Hand-Held-Devices}

  Hand-Held-Devices sind Geräte, die ein Nutzer in der Hand hält.
  Diese Kategorie besteht heutzutage hauptsächlich aus Smartphones und Tablets, da die meisten dieser Geräte über eine Kamera und einen Bildschirm verfügen, können sie fast alle für die Darstellung von AR-Inhalten genutzt werden.
  Das Smartphone oder Tablet ist dabei wie ein Fenster in die digitale Welt, durch das der Nutzer die erweiterte Realität sehen kann.

  Die Immersion ist bei diesem Anzeigegerät jedoch relativ gering, da der Nutzer immer die reale Welt sieht und das Smartphone oder Tablet nur ein kleines Fenster in die digitale Welt ist.
  Allein durch die Entfernung der Geräte vom den Augen der Nutzer können sie nur ein vergleichsweise kleines Sichtfeld abdecken.

  Jedoch ist die Nutzung von Smartphones für AR sehr weit verbreitet, da fast jeder ein Smartphone besitzt und so keine zusätzliche Hardware benötigt wird.
  Beispielsweise hatte das AR-Spiel Pok\'emon Go, welches 2016 veröffentlicht wurde, bereits Anfang 2019 über 1 Milliarde Downloads \autocite[][]{pokemon-go-stats}.
  Bei dem Spiel werden Pok\'emon über die Smartphone-Kamera in die reale Welt projiziert, sodass der Nutzer sie fangen kann.
  Der Erfolg dieses simplen Konzepts zeigt das Potenzial der riesigen Nutzergruppe von Smartphones für AR-Anwendungen.

  Auch können Smartphones als Displays für HMDs genutzt werden.
  Dabei ist jedoch meist die Kamera des Smartphones nicht mehr nutzbar, wodurch normalerweise die Wiedergabe von AR-Inhalten nicht möglich ist.
  Zudem ist die Pixeldichte von Smartphones meist geringer als bei speziellen AR-Anzeigegeräten, was die Immersion und Nutzererfahrung verschlechtern kann, da das Display sehr nah an den Augen des Nutzers ist.

  

  \subsection{Spatial Displays}

  Die bisher vorgestellten Konzepte für AR-Anzeigegeräte basieren auf Displays die direkt am Nutzer selbst befestigt sind.
  Im Kontrast dazu ist die meiste Technik bei Spatial Displays in der Umgebung des Nutzers verbaut.
  Der Nutzer selbst muss dabei keine spezielle Hardware tragen um die AR-Inhalte zu sehen \autocite[]{bimber2006modern}.
  Jedoch können beispielsweise zur Interaktion mit Inhalten Eingabegeräte genutzt werden, die der Nutzer in der Hand hält.

  Da in vielen Fällen keine spezielle Hardware am Nutzer selbst befestigt werden muss, kann die Immersion durch Spatial Displays sehr hoch sein.
  Auch das ergonomische Nutzererlebnis über lange Zeiträume kann durch Spatial Displays verbessert werden, da der Nutzer nicht durch das Tragen von schwerer Hardware belastet wird.

  Ein Nachteil von Spatial Displays ist der Abstand der Displays zum Nutzer.
  Da sie weiter vom Nutzer entfernt sind als HMDs oder Hand-Held-Devices können sie mit der gleichen Displaygröße nur ein kleineres Sichtfeld abdecken.
  Daher werden bei Spatial Displays oft sehr große Displays genutzt, um trotzdem ein großes Sichtfeld abzudecken.
  Dadurch sind Spatial Displays deutlich teurer und aufwendiger in der Installation als HMDs oder Hand-Held-Devices.
  Sie werden daher meist in aufwendigen Anwendungen genutzt und sind für den privaten Gebrauch eher ungeeignet.